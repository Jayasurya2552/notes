										AZURE DATAFACTORY NOTES

								datafactory is simply a data integration service

								easy to use, cost effective, powerful for data integration and transformation

								can do ETL processes at scale through spark

								has 90+ connectors to transform the data


										CREATING DATAFACTORY

								create a resoruce group

								create a resource  ---- datafactory

								to create a resorce we need a resource group and region

								remember the naming rules

								MONITORING ----------------------------------- *pipeline works             - how much pipeline runs
																			   *avtivity runs              - activities in pipeline
																			   *trigger runs               - same pipeline in different region
																			   *integration runtime CPU    - to create a runtime to integrate
																			   *integration runtime memory - memory used for integration

								IAM access control ---- important** --- who has access to the resouce

								properties --- has a resouce group ID which used when API calling

								create linked service ------------- has datastore and comnpute types where compute requires no datasets

								create dataset [ prefer parameterized ] , use diff delimeter for using dataset in diff input

								create pipeline

								create containers for input and output


								create storage [ blob storage ]

								LOOK UP - for reading a file

								CHOOSE move and transform ----- read and write

								for reusablity --- use for loop and iterate

								RANGE [ row and column value ]

								MONITOR - [ debugging ]





							    